{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dP0XmTWfNYe0"
   },
   "source": [
    "# Pneumonia Classification using Chest X-Ray Images\n",
    "\n",
    "This notebook implements:\n",
    "- Custom CNN for pneumonia detection\n",
    "- Transfer Learning with ResNet50\n",
    "- Explainable AI (GradCAM) for model interpretation\n",
    "- Model comparison and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6eKV5igMybW"
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics import Accuracy, Precision, Recall, AUROC\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import random\n",
    "import multiprocessing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaEQHXtPPIRm"
   },
   "source": [
    "## Utility Functions\n",
    "\n",
    "Setting up utility functions for reproducibility and device selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnP4ZXGGNjQe"
   },
   "outputs": [],
   "source": [
    "#set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#define device function\n",
    "def get_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('Device:', device)\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        print('Number of GPUs:', torch.cuda.device_count())\n",
    "        print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print('No GPU available, using CPU.')\n",
    "\n",
    "    print('PyTorch Version:', torch.__version__)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhC89cCHPNTb"
   },
   "source": [
    "## Configuration Settings\n",
    "\n",
    "Define constants and settings for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7su5oVcZPOWu"
   },
   "outputs": [],
   "source": [
    "#define constants\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (150, 150)\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_WORKERS = 0  \n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "\n",
    "#set up data paths\n",
    "DATA_PATH = r'E:\\neat\\data set kaggle pnemonia\\chest_xray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SS0ewye0PQZx"
   },
   "source": [
    "## Dataset Implementation\n",
    "\n",
    "Custom dataset class for chest X-ray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LlNz296PRjH"
   },
   "outputs": [],
   "source": [
    "#create datasets and dataloaders\n",
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(self, filenames, transform=None):\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.filenames[idx]\n",
    "        label = 1 if \"PNEUMONIA\" in file_path else 0\n",
    "\n",
    "        #load and process image\n",
    "        img = Image.open(file_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz3Rm3s8PXyG"
   },
   "source": [
    "## Model Architecture Components\n",
    "\n",
    "Define building blocks for the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KczxAUj7PYDX"
   },
   "outputs": [],
   "source": [
    "#define the CNN building blocks\n",
    "def conv_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels), # Apply BatchNorm before activation\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "#fixed dense block function\n",
    "def dense_block(in_features, out_features, dropout_rate):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(dropout_rate)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCft1xtqPbUY"
   },
   "source": [
    "## Custom CNN Model\n",
    "\n",
    "Implementation of the custom CNN architecture for pneumonia classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_woMHZ1aPcbX"
   },
   "outputs": [],
   "source": [
    "#custom CNN model\n",
    "class PneumoniaCNN(nn.Module):\n",
    "    def __init__(self, image_size=(150, 150), num_classes=1):\n",
    "        super(PneumoniaCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = conv_block(3, 32)\n",
    "        self.conv2 = conv_block(32, 64)\n",
    "        self.conv3 = conv_block(64, 128)\n",
    "        self.conv4 = conv_block(128, 256)\n",
    "        self.conv5 = conv_block(256, 512)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        #compute the flattened size\n",
    "        flat_size = self._get_flattened_size((3, image_size[0], image_size[1]))\n",
    "\n",
    "        self.dense1 = dense_block(flat_size, 512, 0.5)\n",
    "        self.dense2 = dense_block(512, 128, 0.3)\n",
    "        self.fc_out = nn.Linear(128, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def _get_flattened_size(self, shape):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *shape)\n",
    "            dummy_output = self.conv5(self.dropout1(self.conv4(self.conv3(self.conv2(self.conv1(dummy_input))))))\n",
    "            return dummy_output.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.fc_out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVknn5qePeO1"
   },
   "source": [
    "## Loss Function and Early Stopping\n",
    "\n",
    "Implementing Focal Loss for class imbalance and Early Stopping for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "u3_cD1eNPfge",
    "outputId": "a3ad9d4a-838b-4b48-c2c1-dfbaa9a5bd66"
   },
   "outputs": [],
   "source": [
    "#define Focal Loss for better handling of class imbalance\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = nn.BCELoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = self.bce(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "#early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=True, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72OoVXmYPjsv"
   },
   "source": [
    "## Training and Evaluation Functions\n",
    "\n",
    "Functions for training epochs and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SM6UDmU_Pj7-"
   },
   "outputs": [],
   "source": [
    "#training and evaluation functions\n",
    "def train_epoch(model, dataloader, optimizer, criterion, class_weights, device, grad_clip=1.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    #initialize metrics\n",
    "    accuracy_metric = Accuracy(task=\"binary\").to(device)\n",
    "    precision_metric = Precision(task=\"binary\").to(device)\n",
    "    recall_metric = Recall(task=\"binary\").to(device)\n",
    "    auroc_metric = AUROC(task=\"binary\").to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward pass\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        #apply class weights if using BCELoss\n",
    "        if isinstance(criterion, nn.BCELoss):\n",
    "            batch_weights = torch.where(labels == 1, class_weights[1], class_weights[0])\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = (loss * batch_weights).mean()\n",
    "        else:\n",
    "            #for focalLoss we don't need to apply weights separately\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #gradient clipping to prevent exploding gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        #optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        #statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #convert outputs to predictions\n",
    "        preds = (outputs > 0.5).float()\n",
    "\n",
    "        #update metrics\n",
    "        accuracy_metric.update(preds, labels)\n",
    "        precision_metric.update(preds, labels)\n",
    "        recall_metric.update(preds, labels)\n",
    "\n",
    "        #collect predictions and labels for AUROC\n",
    "        all_preds.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    #compute all metrics\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    auroc_metric.update(all_preds, all_labels)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': running_loss / len(dataloader),\n",
    "        'accuracy': accuracy_metric.compute().item(),\n",
    "        'precision': precision_metric.compute().item(),\n",
    "        'recall': recall_metric.compute().item(),\n",
    "        'auroc': auroc_metric.compute().item()\n",
    "    }\n",
    "\n",
    "    #reset metrics\n",
    "    accuracy_metric.reset()\n",
    "    precision_metric.reset()\n",
    "    recall_metric.reset()\n",
    "    auroc_metric.reset()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    #initialize metrics\n",
    "    accuracy_metric = Accuracy(task=\"binary\").to(device)\n",
    "    precision_metric = Precision(task=\"binary\").to(device)\n",
    "    recall_metric = Recall(task=\"binary\").to(device)\n",
    "    auroc_metric = AUROC(task=\"binary\").to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #forward pass\n",
    "            outputs = model(images).squeeze()\n",
    "\n",
    "            #loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            #convert outputs to predictions\n",
    "            preds = (outputs > 0.5).float()\n",
    "\n",
    "            #update metrics\n",
    "            accuracy_metric.update(preds, labels)\n",
    "            precision_metric.update(preds, labels)\n",
    "            recall_metric.update(preds, labels)\n",
    "\n",
    "            #collect predictions and labels for AUROC\n",
    "            all_outputs.append(outputs.detach().cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    #compute all metrics\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    auroc_metric.update(all_outputs, all_labels)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': running_loss / len(dataloader),\n",
    "        'accuracy': accuracy_metric.compute().item(),\n",
    "        'precision': precision_metric.compute().item(),\n",
    "        'recall': recall_metric.compute().item(),\n",
    "        'auroc': auroc_metric.compute().item(),\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'outputs': all_outputs\n",
    "    }\n",
    "\n",
    "    #reset metrics\n",
    "    accuracy_metric.reset()\n",
    "    precision_metric.reset()\n",
    "    recall_metric.reset()\n",
    "    auroc_metric.reset()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duK2-cq9PryA"
   },
   "source": [
    "## GradCAM Implementation\n",
    "\n",
    "Gradient-weighted Class Activation Mapping for model interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wZO2xm_Ps6m"
   },
   "outputs": [],
   "source": [
    "#simple GradCAM implementation\n",
    "def simple_gradcam(model, input_tensor, target_layer, device):\n",
    "    \"\"\"\n",
    "    Simple GradCAM implementation without external libraries\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        input_tensor: Input tensor (already properly shaped)\n",
    "        target_layer: Layer to visualize\n",
    "        device: Device to run on\n",
    "    \"\"\"\n",
    "    #ensure input is on the correct device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    input_tensor.requires_grad_(True)\n",
    "\n",
    "    #set model to eval\n",
    "    model.eval()\n",
    "\n",
    "    #register hooks to get gradients and activations\n",
    "    activations = []\n",
    "    gradients = []\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output.detach())\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0].detach())\n",
    "\n",
    "    handle_forward = target_layer.register_forward_hook(forward_hook)\n",
    "    handle_backward = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    #forward pass\n",
    "    model.zero_grad()\n",
    "    output = model(input_tensor)\n",
    "\n",
    "    #get target \n",
    "    target = torch.ones(output.shape).to(device)\n",
    "\n",
    "    \n",
    "    output.backward(gradient=target)\n",
    "\n",
    "    handle_forward.remove()\n",
    "    handle_backward.remove()\n",
    "\n",
    "    #check if we have gradients and activations\n",
    "    if not gradients or not activations:\n",
    "        print(\"No gradients or activations captured\")\n",
    "        return np.zeros((input_tensor.shape[2], input_tensor.shape[3]))\n",
    "\n",
    "    #calculate weights\n",
    "    pooled_gradients = torch.mean(gradients[0], dim=[0, 2, 3])\n",
    "\n",
    "    #weight the channels by corresponding gradients\n",
    "    activation = activations[0]\n",
    "\n",
    "    #create a weighted combination of the activation maps\n",
    "    weighted_activation = torch.zeros_like(activation)\n",
    "    for i in range(pooled_gradients.shape[0]):\n",
    "        weighted_activation[:, i, :, :] = activation[:, i, :, :] * pooled_gradients[i]\n",
    "\n",
    "    #average the channels of the activations\n",
    "    heatmap = torch.mean(weighted_activation, dim=1).squeeze()\n",
    "\n",
    "    #ReLU on top of the heatmap\n",
    "    heatmap = F.relu(heatmap)\n",
    "\n",
    "    #Normalize\n",
    "    heatmap = heatmap / (torch.max(heatmap) + 1e-10)\n",
    "\n",
    "    return heatmap.cpu().numpy()\n",
    "\n",
    "def visualize_simple_gradcam(model, dataloader, device, save_path, num_images=5):\n",
    "    \"\"\"save GradCAM visualizations using simple implementation\"\"\"\n",
    "    model.eval()\n",
    "    images_processed = 0\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    #determine target layer based on model type\n",
    "    if hasattr(model, 'conv5'):\n",
    "        target_layer = model.conv5[0]  \n",
    "    else:  \n",
    "        target_layer = model.layer4[-1].conv2  \n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        batch_size = inputs.size(0)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if images_processed >= num_images:\n",
    "                return\n",
    "\n",
    "            #process single image\n",
    "            input_tensor = inputs[j:j+1].to(device) \n",
    "\n",
    "            try:\n",
    "                #get prediction\n",
    "                with torch.no_grad():\n",
    "                    output = model(input_tensor)\n",
    "                    pred = (output > 0.5).float().item()\n",
    "\n",
    "                #get heatmap\n",
    "                heatmap = simple_gradcam(model, input_tensor, target_layer, device)\n",
    "\n",
    "                if heatmap.shape != (input_tensor.shape[2], input_tensor.shape[3]):\n",
    "                    heatmap = cv2.resize(heatmap, (input_tensor.shape[3], input_tensor.shape[2]))\n",
    "\n",
    "                #get original image for visualization\n",
    "                img = inputs[j].permute(1, 2, 0).numpy()\n",
    "                #denormalize\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "\n",
    "                #create visualization\n",
    "                plt.figure(figsize=(12, 4))\n",
    "\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title('Original Image')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(heatmap, cmap='jet')\n",
    "                plt.title('GradCAM Heatmap')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.imshow(img)\n",
    "                plt.imshow(heatmap, alpha=0.5, cmap='jet')\n",
    "                plt.title(f'Overlay (Pred: {pred:.0f}, True: {labels[j].item():.0f})')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_path, f'gradcam_{images_processed}.png'))\n",
    "                plt.close()\n",
    "\n",
    "                images_processed += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {j}: {e}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP6y85fXPvE8"
   },
   "source": [
    "## Visualization Functions\n",
    "\n",
    "Functions for plotting learning curves and model comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RxvM_u5Pxoj"
   },
   "outputs": [],
   "source": [
    "#visualization functions\n",
    "def plot_learning_curves(train_metrics, val_metrics, save_path):\n",
    "    \"\"\"Plot learning curves from training metrics\"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    metrics = ['loss', 'accuracy', 'precision', 'recall', 'auroc']\n",
    "    titles = ['Loss', 'Accuracy', 'Precision', 'Recall', 'AUROC']\n",
    "\n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "        plt.subplot(3, 2, i+1)\n",
    "        plt.plot(train_metrics[metric], label=f'Train {title}')\n",
    "        plt.plot(val_metrics[metric], label=f'Validation {title}')\n",
    "        plt.title(f'Training and Validation {title}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(title)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def compare_models(custom_metrics, transfer_metrics, save_path):\n",
    "    \"\"\"Create comparison charts for model performance\"\"\"\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'auroc']\n",
    "\n",
    "    #bar chart comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "\n",
    "    custom_values = [custom_metrics[m] for m in metrics]\n",
    "    transfer_values = [transfer_metrics[m] for m in metrics]\n",
    "\n",
    "    plt.bar(x - width/2, custom_values, width, label='Custom CNN')\n",
    "    plt.bar(x + width/2, transfer_values, width, label='Transfer Learning (ResNet50)')\n",
    "\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1.0)\n",
    "\n",
    "    #add value labels\n",
    "    for i, v in enumerate(custom_values):\n",
    "        plt.text(i - width/2, v + 0.02, f'{v:.3f}', ha='center')\n",
    "\n",
    "    for i, v in enumerate(transfer_values):\n",
    "        plt.text(i + width/2, v + 0.02, f'{v:.3f}', ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooIp4BfXP056"
   },
   "source": [
    "## Main Training and Evaluation Code\n",
    "\n",
    "The main function for training and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bre57EA-P1Fq"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = get_device()\n",
    "\n",
    "    set_seed()\n",
    "\n",
    "    #create checkpoint directory\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "    #load data paths\n",
    "    train_filenames = glob.glob(os.path.join(DATA_PATH, 'train/*/*'))\n",
    "    val_filenames = glob.glob(os.path.join(DATA_PATH, 'val/*/*'))\n",
    "    test_filenames = glob.glob(os.path.join(DATA_PATH, 'test/*/*'))\n",
    "\n",
    "    #combine train and val for better splitting\n",
    "    all_train_filenames = train_filenames + val_filenames\n",
    "    train_filenames, val_filenames = train_test_split(\n",
    "        all_train_filenames,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=[1 if \"PNEUMONIA\" in f else 0 for f in all_train_filenames]\n",
    "    )\n",
    "\n",
    "    #count class distribution\n",
    "    COUNT_NORMAL_TRAIN = len([f for f in train_filenames if \"NORMAL\" in f])\n",
    "    COUNT_PNEUMONIA_TRAIN = len([f for f in train_filenames if \"PNEUMONIA\" in f])\n",
    "    TRAIN_IMG_COUNT = len(train_filenames)\n",
    "    VAL_IMG_COUNT = len(val_filenames)\n",
    "    TEST_IMG_COUNT = len(test_filenames)\n",
    "\n",
    "    print(f\"Training images: {TRAIN_IMG_COUNT} (Normal: {COUNT_NORMAL_TRAIN}, Pneumonia: {COUNT_PNEUMONIA_TRAIN})\")\n",
    "    print(f\"Validation images: {VAL_IMG_COUNT}\")\n",
    "    print(f\"Test images: {TEST_IMG_COUNT}\")\n",
    "\n",
    "    #calculate class weights for handling imbalance\n",
    "    weight_for_0 = (1 / COUNT_NORMAL_TRAIN) * (TRAIN_IMG_COUNT) / 2.0\n",
    "    weight_for_1 = (1 / COUNT_PNEUMONIA_TRAIN) * (TRAIN_IMG_COUNT) / 2.0\n",
    "    class_weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float32).to(device)\n",
    "    print(f'Weight for class 0 (Normal): {weight_for_0:.2f}')\n",
    "    print(f'Weight for class 1 (Pneumonia): {weight_for_1:.2f}')\n",
    "\n",
    "    #data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    #create datasets\n",
    "    train_ds = ChestXRayDataset(train_filenames, transform=train_transform)\n",
    "    val_ds = ChestXRayDataset(val_filenames, transform=val_transform)\n",
    "    test_ds = ChestXRayDataset(test_filenames, transform=val_transform)\n",
    "\n",
    "    #create dataloaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    #initialize the model, loss, and optimizer\n",
    "    model = PneumoniaCNN(image_size=IMAGE_SIZE).to(device)\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0)  # Use Focal Loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    #set up TensorBoard for logging\n",
    "    writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "    #get a batch to verify shapes\n",
    "    for images, labels in train_loader:\n",
    "        print(f\"Batch image shape: {images.shape}\")\n",
    "        print(f\"Batch label shape: {labels.shape}\")\n",
    "        break\n",
    "\n",
    "    #initialize tracking metrics\n",
    "    train_history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auroc': []}\n",
    "    val_history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auroc': []}\n",
    "\n",
    "    #main training loop with Early Stopping\n",
    "    early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, verbose=True, path=os.path.join(CHECKPOINT_DIR, 'best_model.pt'))\n",
    "\n",
    "    print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        #train\n",
    "        train_metrics = train_epoch(model, train_loader, optimizer, criterion, class_weights, device)\n",
    "\n",
    "        #evaluate\n",
    "        val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        #store metrics history\n",
    "        for metric in train_metrics:\n",
    "            if metric in train_history:\n",
    "                train_history[metric].append(train_metrics[metric])\n",
    "                val_history[metric].append(val_metrics[metric])\n",
    "\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "\n",
    "        #print statistics\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "        print(f\"  Train: Loss={train_metrics['loss']:.4f}, Acc={train_metrics['accuracy']:.4f}, Prec={train_metrics['precision']:.4f}, Rec={train_metrics['recall']:.4f}, AUROC={train_metrics['auroc']:.4f}\")\n",
    "        print(f\"  Val:   Loss={val_metrics['loss']:.4f}, Acc={val_metrics['accuracy']:.4f}, Prec={val_metrics['precision']:.4f}, Rec={val_metrics['recall']:.4f}, AUROC={val_metrics['auroc']:.4f}\")\n",
    "\n",
    "        #log to TensorBoard\n",
    "        writer.add_scalars('Loss', {'train': train_metrics['loss'], 'val': val_metrics['loss']}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'train': train_metrics['accuracy'], 'val': val_metrics['accuracy']}, epoch)\n",
    "        writer.add_scalars('Precision', {'train': train_metrics['precision'], 'val': val_metrics['precision']}, epoch)\n",
    "        writer.add_scalars('Recall', {'train': train_metrics['recall'], 'val': val_metrics['recall']}, epoch)\n",
    "\n",
    "        #early stopping\n",
    "        early_stopping(val_metrics['loss'], model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    #plot learning curves\n",
    "    plot_learning_curves(train_history, val_history, os.path.join(CHECKPOINT_DIR, 'learning_curves.png'))\n",
    "\n",
    "    #load the best model and evaluate on test set\n",
    "    print(\"Loading best model and evaluating on test set...\")\n",
    "    model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pt')))\n",
    "    test_metrics = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(\"\\nCustom CNN Test Results:\")\n",
    "    print(f\"  Loss: {test_metrics['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"  AUROC: {test_metrics['auroc']:.4f}\")\n",
    "\n",
    "    #generate classification report for custom model\n",
    "    custom_report = classification_report(\n",
    "        test_metrics['labels'].numpy(),\n",
    "        test_metrics['predictions'].numpy(),\n",
    "        target_names=['Normal', 'Pneumonia'],\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    #print detailed class-wise results for Custom CNN\n",
    "    print(\"\\nCustom CNN Class-wise Results:\")\n",
    "    print(f\"Normal class:\")\n",
    "    print(f\"  Precision: {custom_report['Normal']['precision']:.4f}\")\n",
    "    print(f\"  Recall: {custom_report['Normal']['recall']:.4f}\")\n",
    "    print(f\"  F1-Score: {custom_report['Normal']['f1-score']:.4f}\")\n",
    "    print(f\"  Support: {int(custom_report['Normal']['support'])}\")\n",
    "\n",
    "    print(f\"Pneumonia class:\")\n",
    "    print(f\"  Precision: {custom_report['Pneumonia']['precision']:.4f}\")\n",
    "    print(f\"  Recall: {custom_report['Pneumonia']['recall']:.4f}\")\n",
    "    print(f\"  F1-Score: {custom_report['Pneumonia']['f1-score']:.4f}\")\n",
    "    print(f\"  Support: {int(custom_report['Pneumonia']['support'])}\")\n",
    "\n",
    "    #visualizations and Analysis for Custom CNN\n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    \n",
    "    #confusion Matrix\n",
    "    print(\"Creating confusion matrix...\")\n",
    "    cm = confusion_matrix(test_metrics['labels'].numpy(), test_metrics['predictions'].numpy())\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - Custom CNN')\n",
    "    plt.savefig(os.path.join(CHECKPOINT_DIR, 'custom_confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "    #ROC Curve\n",
    "    print(\"Creating ROC curve...\")\n",
    "    fpr, tpr, _ = roc_curve(test_metrics['labels'].numpy(), test_metrics['outputs'].numpy())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Custom CNN')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(CHECKPOINT_DIR, 'custom_roc_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "    #GradCAM visualizations for model interpretability\n",
    "    print(\"Generating GradCAM visualizations...\")\n",
    "    gradcam_dir = os.path.join(CHECKPOINT_DIR, 'gradcam_custom')\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "    visualize_simple_gradcam(model, test_loader, device, gradcam_dir, num_images=5)\n",
    "\n",
    "    #store metrics for comparison\n",
    "    custom_results = {\n",
    "        'accuracy': test_metrics['accuracy'],\n",
    "        'precision': test_metrics['precision'],\n",
    "        'recall': test_metrics['recall'],\n",
    "        'auroc': test_metrics['auroc']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nCustom CNN evaluation complete. Results saved to: {CHECKPOINT_DIR}\")\n",
    "    \n",
    "    #return important variables that might be needed for further analysis\n",
    "    return model, test_loader, device, custom_results, custom_report, test_metrics, class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Training Pipeline\n",
    "\n",
    "Execute the main function with proper multiprocessing support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1Snhp7PZQE-F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "PyTorch Version: 2.5.1\n",
      "Training images: 4185 (Normal: 1079, Pneumonia: 3106)\n",
      "Validation images: 1047\n",
      "Test images: 624\n",
      "Weight for class 0 (Normal): 1.94\n",
      "Weight for class 1 (Pneumonia): 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch image shape: torch.Size([32, 3, 150, 150])\n",
      "Batch label shape: torch.Size([32])\n",
      "Starting training for 20 epochs...\n",
      "Epoch [1/20]\n",
      "  Train: Loss=0.0231, Acc=0.8370, Prec=0.8734, Rec=0.9127, AUROC=0.8917\n",
      "  Val:   Loss=0.0119, Acc=0.9398, Prec=0.9648, Rec=0.9537, AUROC=0.9815\n",
      "Validation loss decreased (inf --> 0.011896). Saving model...\n",
      "Epoch [2/20]\n",
      "  Train: Loss=0.0140, Acc=0.9142, Prec=0.9415, Rec=0.9430, AUROC=0.9642\n",
      "  Val:   Loss=0.0189, Acc=0.8730, Prec=0.9969, Rec=0.8314, AUROC=0.9908\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [3/20]\n",
      "  Train: Loss=0.0093, Acc=0.9470, Prec=0.9661, Rec=0.9623, AUROC=0.9843\n",
      "  Val:   Loss=0.0065, Acc=0.9561, Prec=0.9574, Rec=0.9846, AUROC=0.9936\n",
      "Validation loss decreased (0.011896 --> 0.006508). Saving model...\n",
      "Epoch [4/20]\n",
      "  Train: Loss=0.0088, Acc=0.9524, Prec=0.9666, Rec=0.9694, AUROC=0.9859\n",
      "  Val:   Loss=0.0076, Acc=0.9589, Prec=0.9973, Rec=0.9472, AUROC=0.9962\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [5/20]\n",
      "  Train: Loss=0.0071, Acc=0.9615, Prec=0.9758, Rec=0.9723, AUROC=0.9910\n",
      "  Val:   Loss=0.0052, Acc=0.9780, Prec=0.9909, Rec=0.9794, AUROC=0.9953\n",
      "Validation loss decreased (0.006508 --> 0.005199). Saving model...\n",
      "Epoch [6/20]\n",
      "  Train: Loss=0.0076, Acc=0.9596, Prec=0.9726, Rec=0.9730, AUROC=0.9895\n",
      "  Val:   Loss=0.0046, Acc=0.9761, Prec=0.9808, Rec=0.9871, AUROC=0.9964\n",
      "Validation loss decreased (0.005199 --> 0.004626). Saving model...\n",
      "Epoch [7/20]\n",
      "  Train: Loss=0.0065, Acc=0.9661, Prec=0.9762, Rec=0.9781, AUROC=0.9923\n",
      "  Val:   Loss=0.0046, Acc=0.9733, Prec=0.9845, Rec=0.9794, AUROC=0.9966\n",
      "Validation loss decreased (0.004626 --> 0.004580). Saving model...\n",
      "Epoch [8/20]\n",
      "  Train: Loss=0.0060, Acc=0.9649, Prec=0.9747, Rec=0.9781, AUROC=0.9935\n",
      "  Val:   Loss=0.0053, Acc=0.9780, Prec=0.9883, Rec=0.9820, AUROC=0.9959\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [9/20]\n",
      "  Train: Loss=0.0063, Acc=0.9687, Prec=0.9778, Rec=0.9800, AUROC=0.9929\n",
      "  Val:   Loss=0.0160, Acc=0.9236, Prec=0.9986, Rec=0.8983, AUROC=0.9966\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [10/20]\n",
      "  Train: Loss=0.0066, Acc=0.9651, Prec=0.9756, Rec=0.9775, AUROC=0.9920\n",
      "  Val:   Loss=0.0041, Acc=0.9790, Prec=0.9909, Rec=0.9807, AUROC=0.9972\n",
      "Validation loss decreased (0.004580 --> 0.004097). Saving model...\n",
      "Epoch [11/20]\n",
      "  Train: Loss=0.0052, Acc=0.9732, Prec=0.9804, Rec=0.9836, AUROC=0.9951\n",
      "  Val:   Loss=0.0052, Acc=0.9742, Prec=0.9735, Rec=0.9923, AUROC=0.9975\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [12/20]\n",
      "  Train: Loss=0.0052, Acc=0.9694, Prec=0.9800, Rec=0.9788, AUROC=0.9952\n",
      "  Val:   Loss=0.0046, Acc=0.9761, Prec=0.9947, Rec=0.9730, AUROC=0.9978\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [13/20]\n",
      "  Train: Loss=0.0046, Acc=0.9730, Prec=0.9810, Rec=0.9826, AUROC=0.9961\n",
      "  Val:   Loss=0.0043, Acc=0.9742, Prec=0.9896, Rec=0.9755, AUROC=0.9969\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch [14/20]\n",
      "  Train: Loss=0.0049, Acc=0.9754, Prec=0.9814, Rec=0.9855, AUROC=0.9957\n",
      "  Val:   Loss=0.0048, Acc=0.9733, Prec=0.9921, Rec=0.9717, AUROC=0.9975\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch [15/20]\n",
      "  Train: Loss=0.0039, Acc=0.9790, Prec=0.9861, Rec=0.9855, AUROC=0.9973\n",
      "  Val:   Loss=0.0042, Acc=0.9761, Prec=0.9896, Rec=0.9781, AUROC=0.9978\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered!\n",
      "Loading best model and evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1764\\3039016317.py:131: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pt')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom CNN Test Results:\n",
      "  Loss: 0.0537\n",
      "  Accuracy: 0.7804\n",
      "  Precision: 0.7410\n",
      "  Recall: 0.9974\n",
      "  AUROC: 0.9480\n",
      "\n",
      "Custom CNN Class-wise Results:\n",
      "Normal class:\n",
      "  Precision: 0.9899\n",
      "  Recall: 0.4188\n",
      "  F1-Score: 0.5886\n",
      "  Support: 234\n",
      "Pneumonia class:\n",
      "  Precision: 0.7410\n",
      "  Recall: 0.9974\n",
      "  F1-Score: 0.8503\n",
      "  Support: 390\n",
      "\n",
      "Generating visualizations...\n",
      "Creating confusion matrix...\n",
      "Creating ROC curve...\n",
      "Generating GradCAM visualizations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom CNN evaluation complete. Results saved to: checkpoints\n",
      "\n",
      "\n",
      "==================================================\n",
      "Starting transfer learning model training and evaluation...\n",
      "Custom CNN fpr and tpr are available for comparison with transfer learning results.\n",
      "\n",
      "Execution complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #this is crucial for windows multiprocessing\n",
    "    multiprocessing.freeze_support()\n",
    "    \n",
    "    #run main function and capture returned variables\n",
    "    model, test_loader, device, custom_results, custom_report, test_metrics, class_weights = main()\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\"*50)\n",
    "    print(\"Starting transfer learning model training and evaluation...\")\n",
    "    \n",
    "    print(\"Custom CNN fpr and tpr are available for comparison with transfer learning results.\")\n",
    "    \n",
    "    print(\"\\nExecution complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAfGI8k-P5YF"
   },
   "source": [
    "## Transfer Learning with ResNet50\n",
    "\n",
    "Training a model using transfer learning with ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfY1fC4NP5nu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Training Transfer Learning Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "d:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "  Train: Loss=0.0141, Acc=0.9262, Prec=0.9597, Rec=0.9401, AUROC=0.9727\n",
      "  Val:   Loss=0.0378, Acc=0.7500, Prec=0.6667, Rec=1.0000, AUROC=0.8750\n",
      "Validation loss decreased (inf --> 0.037812). Saving model...\n",
      "Epoch [2/20]\n",
      "  Train: Loss=0.0096, Acc=0.9530, Prec=0.9659, Rec=0.9711, AUROC=0.9870\n",
      "  Val:   Loss=0.0351, Acc=0.7500, Prec=0.6667, Rec=1.0000, AUROC=0.9531\n",
      "Validation loss decreased (0.037812 --> 0.035098). Saving model...\n",
      "Epoch [3/20]\n",
      "  Train: Loss=0.0072, Acc=0.9628, Prec=0.9716, Rec=0.9786, AUROC=0.9910\n",
      "  Val:   Loss=0.0456, Acc=0.6250, Prec=0.5714, Rec=1.0000, AUROC=1.0000\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [4/20]\n",
      "  Train: Loss=0.0064, Acc=0.9688, Prec=0.9779, Rec=0.9801, AUROC=0.9930\n",
      "  Val:   Loss=0.0400, Acc=0.6875, Prec=0.6154, Rec=1.0000, AUROC=0.9688\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [5/20]\n",
      "  Train: Loss=0.0058, Acc=0.9726, Prec=0.9797, Rec=0.9835, AUROC=0.9943\n",
      "  Val:   Loss=0.0259, Acc=0.8125, Prec=0.7273, Rec=1.0000, AUROC=1.0000\n",
      "Validation loss decreased (0.035098 --> 0.025941). Saving model...\n",
      "Epoch [6/20]\n",
      "  Train: Loss=0.0049, Acc=0.9755, Prec=0.9857, Rec=0.9812, AUROC=0.9957\n",
      "  Val:   Loss=0.0132, Acc=0.8750, Prec=0.8000, Rec=1.0000, AUROC=1.0000\n",
      "Validation loss decreased (0.025941 --> 0.013232). Saving model...\n",
      "Epoch [7/20]\n",
      "  Train: Loss=0.0047, Acc=0.9751, Prec=0.9815, Rec=0.9850, AUROC=0.9959\n",
      "  Val:   Loss=0.0219, Acc=0.8750, Prec=0.8000, Rec=1.0000, AUROC=1.0000\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [8/20]\n",
      "  Train: Loss=0.0044, Acc=0.9764, Prec=0.9860, Rec=0.9822, AUROC=0.9966\n",
      "  Val:   Loss=0.0191, Acc=0.9375, Prec=0.8889, Rec=1.0000, AUROC=1.0000\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [9/20]\n",
      "  Train: Loss=0.0041, Acc=0.9781, Prec=0.9855, Rec=0.9850, AUROC=0.9970\n",
      "  Val:   Loss=0.0218, Acc=0.9375, Prec=0.8889, Rec=1.0000, AUROC=1.0000\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch [10/20]\n",
      "  Train: Loss=0.0045, Acc=0.9758, Prec=0.9835, Rec=0.9840, AUROC=0.9962\n",
      "  Val:   Loss=0.0276, Acc=0.8125, Prec=0.7273, Rec=1.0000, AUROC=1.0000\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch [11/20]\n",
      "  Train: Loss=0.0037, Acc=0.9816, Prec=0.9896, Rec=0.9855, AUROC=0.9978\n",
      "  Val:   Loss=0.0262, Acc=0.8750, Prec=0.8000, Rec=1.0000, AUROC=1.0000\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1764\\1028120437.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_transfer_model.pt')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer Learning Test Results:\n",
      "  Loss: 0.0295\n",
      "  Accuracy: 0.8766\n",
      "  Precision: 0.8410\n",
      "  Recall: 0.9897\n",
      "  AUROC: 0.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    }
   ],
   "source": [
    "#define device before using it\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "#recreate data loaders\n",
    "DATA_PATH = r'E:\\neat\\data set kaggle pnemonia\\chest_xray' \n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (150, 150)\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "train_filenames = glob.glob(os.path.join(DATA_PATH, 'train/*/*'))\n",
    "val_filenames = glob.glob(os.path.join(DATA_PATH, 'val/*/*'))\n",
    "test_filenames = glob.glob(os.path.join(DATA_PATH, 'test/*/*'))\n",
    "\n",
    "#count class distribution for class weights\n",
    "COUNT_NORMAL_TRAIN = len([f for f in train_filenames if \"NORMAL\" in f])\n",
    "COUNT_PNEUMONIA_TRAIN = len([f for f in train_filenames if \"PNEUMONIA\" in f])\n",
    "TRAIN_IMG_COUNT = len(train_filenames)\n",
    "\n",
    "#calculate class weights\n",
    "weight_for_0 = (1 / COUNT_NORMAL_TRAIN) * (TRAIN_IMG_COUNT) / 2.0\n",
    "weight_for_1 = (1 / COUNT_PNEUMONIA_TRAIN) * (TRAIN_IMG_COUNT) / 2.0\n",
    "class_weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float32).to(device)\n",
    "\n",
    "#create transforms\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#create datasets\n",
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(self, filenames, transform=None):\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.filenames[idx]\n",
    "        label = 1 if \"PNEUMONIA\" in file_path else 0\n",
    "\n",
    "        #load and process image\n",
    "        img = Image.open(file_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "#create dataset instances\n",
    "train_ds = ChestXRayDataset(train_filenames, transform=train_transform)\n",
    "val_ds = ChestXRayDataset(val_filenames, transform=val_transform)\n",
    "test_ds = ChestXRayDataset(test_filenames, transform=val_transform)\n",
    "\n",
    "#create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "#transfer learning model\n",
    "print(\"\\nTraining Transfer Learning Model...\")\n",
    "\n",
    "#initialize model\n",
    "pretrained_model = models.resnet50(pretrained=True)\n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "\n",
    "#modify the final layer for binary classification\n",
    "pretrained_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "#freeze early layers\n",
    "for param in list(pretrained_model.parameters())[:-36]:  # Freeze all except the last few layers\n",
    "    param.requires_grad = False\n",
    "\n",
    "#optimizer and loss for transfer learning\n",
    "transfer_criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "transfer_optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, pretrained_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "transfer_scheduler = ReduceLROnPlateau(\n",
    "    transfer_optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "#early stopping for transfer learning\n",
    "transfer_early_stopping = EarlyStopping(\n",
    "    patience=EARLY_STOPPING_PATIENCE,\n",
    "    verbose=True,\n",
    "    path=os.path.join(CHECKPOINT_DIR, 'best_transfer_model.pt')\n",
    ")\n",
    "\n",
    "#initialize history for transfer learning\n",
    "transfer_train_history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auroc': []}\n",
    "transfer_val_history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auroc': []}\n",
    "\n",
    "#train the transfer learning model\n",
    "for epoch in range(EPOCHS):\n",
    "    #train\n",
    "    train_metrics = train_epoch(\n",
    "        pretrained_model,\n",
    "        train_loader,\n",
    "        transfer_optimizer,\n",
    "        transfer_criterion,\n",
    "        class_weights,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    #evaluate\n",
    "    val_metrics = evaluate(pretrained_model, val_loader, transfer_criterion, device)\n",
    "\n",
    "    #store metrics history\n",
    "    for metric in train_metrics:\n",
    "        if metric in transfer_train_history:\n",
    "            transfer_train_history[metric].append(train_metrics[metric])\n",
    "            transfer_val_history[metric].append(val_metrics[metric])\n",
    "\n",
    "    #scheduler step\n",
    "    transfer_scheduler.step(val_metrics['loss'])\n",
    "\n",
    "    #print statistics\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "    print(f\"  Train: Loss={train_metrics['loss']:.4f}, Acc={train_metrics['accuracy']:.4f}, Prec={train_metrics['precision']:.4f}, Rec={train_metrics['recall']:.4f}, AUROC={train_metrics['auroc']:.4f}\")\n",
    "    print(f\"  Val:   Loss={val_metrics['loss']:.4f}, Acc={val_metrics['accuracy']:.4f}, Prec={val_metrics['precision']:.4f}, Rec={val_metrics['recall']:.4f}, AUROC={val_metrics['auroc']:.4f}\")\n",
    "\n",
    "    #early stopping\n",
    "    transfer_early_stopping(val_metrics['loss'], pretrained_model)\n",
    "    if transfer_early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "#plot learning curves for transfer learning\n",
    "plot_learning_curves(\n",
    "    transfer_train_history,\n",
    "    transfer_val_history,\n",
    "    os.path.join(CHECKPOINT_DIR, 'transfer_learning_curves.png')\n",
    ")\n",
    "\n",
    "#load best transfer model and evaluate\n",
    "pretrained_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_transfer_model.pt')))\n",
    "transfer_test_metrics = evaluate(pretrained_model, test_loader, transfer_criterion, device)\n",
    "\n",
    "print(\"Transfer Learning Test Results:\")\n",
    "print(f\"  Loss: {transfer_test_metrics['loss']:.4f}\")\n",
    "print(f\"  Accuracy: {transfer_test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {transfer_test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {transfer_test_metrics['recall']:.4f}\")\n",
    "print(f\"  AUROC: {transfer_test_metrics['auroc']:.4f}\")\n",
    "\n",
    "#visualizations and Analysis for Transfer Learning\n",
    "#Confusion Matrix\n",
    "transfer_cm = confusion_matrix(\n",
    "    transfer_test_metrics['labels'].numpy(),\n",
    "    transfer_test_metrics['predictions'].numpy()\n",
    ")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    transfer_cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Normal', 'Pneumonia'],\n",
    "    yticklabels=['Normal', 'Pneumonia']\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Transfer Learning (ResNet50)')\n",
    "plt.savefig(os.path.join(CHECKPOINT_DIR, 'transfer_confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "#ROC Curve\n",
    "transfer_fpr, transfer_tpr, _ = roc_curve(\n",
    "    transfer_test_metrics['labels'].numpy(),\n",
    "    transfer_test_metrics['outputs'].numpy()\n",
    ")\n",
    "transfer_roc_auc = auc(transfer_fpr, transfer_tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(\n",
    "    transfer_fpr,\n",
    "    transfer_tpr,\n",
    "    color='darkorange',\n",
    "    lw=2,\n",
    "    label=f'ROC curve (area = {transfer_roc_auc:.2f})'\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Transfer Learning (ResNet50)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(os.path.join(CHECKPOINT_DIR, 'transfer_roc_curve.png'))\n",
    "plt.close()\n",
    "\n",
    "#GradCAM Visualizations for Transfer Learning\n",
    "transfer_gradcam_dir = os.path.join(CHECKPOINT_DIR, 'gradcam_transfer')\n",
    "os.makedirs(transfer_gradcam_dir, exist_ok=True)\n",
    "visualize_simple_gradcam(pretrained_model, test_loader, device, transfer_gradcam_dir, num_images=5)\n",
    "\n",
    "#Classification Report\n",
    "transfer_report = classification_report(\n",
    "    transfer_test_metrics['labels'].numpy(),\n",
    "    transfer_test_metrics['predictions'].numpy(),\n",
    "    target_names=['Normal', 'Pneumonia'],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "#store metrics for comparison\n",
    "transfer_results = {\n",
    "    'accuracy': transfer_test_metrics['accuracy'],\n",
    "    'precision': transfer_test_metrics['precision'],\n",
    "    'recall': transfer_test_metrics['recall'],\n",
    "    'auroc': transfer_test_metrics['auroc']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpNDhu3wP_AF"
   },
   "source": [
    "## Model Comparison and Results\n",
    "\n",
    "Comparing the performance of custom CNN and transfer learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1Y3qgTiP_NJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading best custom model...\n",
      "Custom model loaded successfully.\n",
      "Evaluating custom model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1764\\2506962611.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  custom_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pt')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom CNN Test Results:\n",
      "  Loss: 0.0537\n",
      "  Accuracy: 0.7804\n",
      "  Precision: 0.7410\n",
      "  Recall: 0.9974\n",
      "  AUROC: 0.9480\n",
      "\n",
      "Custom CNN Class-wise Results:\n",
      "Normal class:\n",
      "  Precision: 0.9899\n",
      "  Recall: 0.4188\n",
      "  F1-Score: 0.5886\n",
      "  Support: 234\n",
      "Pneumonia class:\n",
      "  Precision: 0.7410\n",
      "  Recall: 0.9974\n",
      "  F1-Score: 0.8503\n",
      "  Support: 390\n",
      "\n",
      "Transfer Learning Test Results:\n",
      "  Loss: 0.0295\n",
      "  Accuracy: 0.8766\n",
      "  Precision: 0.8410\n",
      "  Recall: 0.9897\n",
      "  AUROC: 0.9451\n",
      "\n",
      "Transfer Learning Class-wise Results:\n",
      "Normal class:\n",
      "  Precision: 0.9758\n",
      "  Recall: 0.6880\n",
      "  F1-Score: 0.8070\n",
      "  Support: 234\n",
      "Pneumonia class:\n",
      "  Precision: 0.8410\n",
      "  Recall: 0.9897\n",
      "  F1-Score: 0.9093\n",
      "  Support: 390\n",
      "\n",
      "Generating comparison visualizations...\n",
      "\n",
      "Model Comparison:\n",
      "      Metric  Custom CNN  Transfer Learning (ResNet50)\n",
      "0   Accuracy    0.780449                      0.876603\n",
      "1  Precision    0.740952                      0.840959\n",
      "2     Recall    0.997436                      0.989744\n",
      "3      AUROC    0.948006                      0.945080\n",
      "\n",
      "Class-wise Performance Comparison:\n",
      "               Model      Class  Precision    Recall  F1-Score\n",
      "0         Custom CNN     Normal   0.989899  0.418803  0.588589\n",
      "1         Custom CNN  Pneumonia   0.740952  0.997436  0.850273\n",
      "2  Transfer Learning     Normal   0.975758  0.688034  0.807018\n",
      "3  Transfer Learning  Pneumonia   0.840959  0.989744  0.909305\n",
      "\n",
      "Training complete! Models and visualizations saved to: checkpoints\n"
     ]
    }
   ],
   "source": [
    "#define constants and paths\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#load the custom model\n",
    "print(\"Loading best custom model...\")\n",
    "custom_model = PneumoniaCNN().to(device)\n",
    "try:\n",
    "    custom_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pt')))\n",
    "    print(\"Custom model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading custom model: {e}\")\n",
    "    print(\"Please run the main() function first to train the custom model.\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "try:\n",
    "    pretrained_model\n",
    "    transfer_test_metrics\n",
    "    transfer_report\n",
    "except NameError:\n",
    "    print(\"Transfer learning model not found.\")\n",
    "    print(\"Please run the transfer learning cell first.\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "#evaluate the custom model on the test set\n",
    "print(\"Evaluating custom model on test set...\")\n",
    "criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "custom_test_metrics = evaluate(custom_model, test_loader, criterion, device)\n",
    "\n",
    "#print overall custom CNN results\n",
    "print(\"\\nCustom CNN Test Results:\")\n",
    "print(f\"  Loss: {custom_test_metrics['loss']:.4f}\")\n",
    "print(f\"  Accuracy: {custom_test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {custom_test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {custom_test_metrics['recall']:.4f}\")\n",
    "print(f\"  AUROC: {custom_test_metrics['auroc']:.4f}\")\n",
    "\n",
    "#generate classification report for custom model\n",
    "custom_report = classification_report(\n",
    "    custom_test_metrics['labels'].numpy(),\n",
    "    custom_test_metrics['predictions'].numpy(),\n",
    "    target_names=['Normal', 'Pneumonia'],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "#print detailed class-wise results for Custom CNN\n",
    "print(\"\\nCustom CNN Class-wise Results:\")\n",
    "print(f\"Normal class:\")\n",
    "print(f\"  Precision: {custom_report['Normal']['precision']:.4f}\")\n",
    "print(f\"  Recall: {custom_report['Normal']['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {custom_report['Normal']['f1-score']:.4f}\")\n",
    "print(f\"  Support: {int(custom_report['Normal']['support'])}\")\n",
    "\n",
    "print(f\"Pneumonia class:\")\n",
    "print(f\"  Precision: {custom_report['Pneumonia']['precision']:.4f}\")\n",
    "print(f\"  Recall: {custom_report['Pneumonia']['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {custom_report['Pneumonia']['f1-score']:.4f}\")\n",
    "print(f\"  Support: {int(custom_report['Pneumonia']['support'])}\")\n",
    "\n",
    "#get ROC curve data for custom model\n",
    "fpr, tpr, _ = roc_curve(\n",
    "    custom_test_metrics['labels'].numpy(),\n",
    "    custom_test_metrics['outputs'].numpy()\n",
    ")\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#store custom model results\n",
    "custom_results = {\n",
    "    'accuracy': custom_test_metrics['accuracy'],\n",
    "    'precision': custom_test_metrics['precision'],\n",
    "    'recall': custom_test_metrics['recall'],\n",
    "    'auroc': custom_test_metrics['auroc']\n",
    "}\n",
    "\n",
    "#print transfer learning results for comparison\n",
    "print(\"\\nTransfer Learning Test Results:\")\n",
    "print(f\"  Loss: {transfer_test_metrics['loss']:.4f}\")\n",
    "print(f\"  Accuracy: {transfer_test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {transfer_test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {transfer_test_metrics['recall']:.4f}\")\n",
    "print(f\"  AUROC: {transfer_test_metrics['auroc']:.4f}\")\n",
    "\n",
    "#print detailed class-wise results for Transfer Learning\n",
    "print(\"\\nTransfer Learning Class-wise Results:\")\n",
    "print(f\"Normal class:\")\n",
    "print(f\"  Precision: {transfer_report['Normal']['precision']:.4f}\")\n",
    "print(f\"  Recall: {transfer_report['Normal']['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {transfer_report['Normal']['f1-score']:.4f}\")\n",
    "print(f\"  Support: {int(transfer_report['Normal']['support'])}\")\n",
    "\n",
    "print(f\"Pneumonia class:\")\n",
    "print(f\"  Precision: {transfer_report['Pneumonia']['precision']:.4f}\")\n",
    "print(f\"  Recall: {transfer_report['Pneumonia']['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {transfer_report['Pneumonia']['f1-score']:.4f}\")\n",
    "print(f\"  Support: {int(transfer_report['Pneumonia']['support'])}\")\n",
    "\n",
    "#compare both models\n",
    "print(\"\\nGenerating comparison visualizations...\")\n",
    "compare_models(\n",
    "    custom_results,\n",
    "    transfer_results,\n",
    "    os.path.join(CHECKPOINT_DIR, 'model_comparison.png')\n",
    ")\n",
    "\n",
    "#create a comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'AUROC'],\n",
    "    'Custom CNN': [custom_results[m] for m in ['accuracy', 'precision', 'recall', 'auroc']],\n",
    "    'Transfer Learning (ResNet50)': [transfer_results[m] for m in ['accuracy', 'precision', 'recall', 'auroc']]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df)\n",
    "comparison_df.to_csv(os.path.join(CHECKPOINT_DIR, 'model_comparison.csv'), index=False)\n",
    "\n",
    "#combined ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color='blue',\n",
    "    lw=2,\n",
    "    label=f'Custom CNN (AUC = {roc_auc:.3f})'\n",
    ")\n",
    "plt.plot(\n",
    "    transfer_fpr,\n",
    "    transfer_tpr,\n",
    "    color='red',\n",
    "    lw=2,\n",
    "    label=f'Transfer Learning (AUC = {transfer_roc_auc:.3f})'\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(os.path.join(CHECKPOINT_DIR, 'combined_roc_curves.png'))\n",
    "plt.close()\n",
    "\n",
    "#create a detailed class-wise performance comparison\n",
    "class_comparison = {\n",
    "    'Model': ['Custom CNN', 'Custom CNN', 'Transfer Learning', 'Transfer Learning'],\n",
    "    'Class': ['Normal', 'Pneumonia', 'Normal', 'Pneumonia'],\n",
    "    'Precision': [\n",
    "        custom_report['Normal']['precision'],\n",
    "        custom_report['Pneumonia']['precision'],\n",
    "        transfer_report['Normal']['precision'],\n",
    "        transfer_report['Pneumonia']['precision']\n",
    "    ],\n",
    "    'Recall': [\n",
    "        custom_report['Normal']['recall'],\n",
    "        custom_report['Pneumonia']['recall'],\n",
    "        transfer_report['Normal']['recall'],\n",
    "        transfer_report['Pneumonia']['recall']\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        custom_report['Normal']['f1-score'],\n",
    "        custom_report['Pneumonia']['f1-score'],\n",
    "        transfer_report['Normal']['f1-score'],\n",
    "        transfer_report['Pneumonia']['f1-score']\n",
    "    ]\n",
    "}\n",
    "\n",
    "class_comparison_df = pd.DataFrame(class_comparison)\n",
    "print(\"\\nClass-wise Performance Comparison:\")\n",
    "print(class_comparison_df)\n",
    "class_comparison_df.to_csv(os.path.join(CHECKPOINT_DIR, 'class_performance_comparison.csv'), index=False)\n",
    "\n",
    "print(\"\\nTraining complete! Models and visualizations saved to:\", CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the limits on google collab I had to run the models locally using my gpu in vscode so there was a problem in showing the plots and visualizations(explainable AI) so they are not shown in the outputs of the notebook but the insights have been mentioned in the document of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
